{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Always install the PySpark module with every runtime!"
      ],
      "metadata": {
        "id": "eCADv3NJwxjf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvFW6zJqprhz",
        "outputId": "62db18dd-e321-4cd1-f1c6-7b34ee5b3f44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=78cb353ffa7e6971f738a846f10fce656c039512de4a4a7967ac02f6734528bf\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import the necessary libraries"
      ],
      "metadata": {
        "id": "HuntW0tww6KT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.classification import NaiveBayes\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "xjmww5jFv-xf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a spark session"
      ],
      "metadata": {
        "id": "wlZ7VpKZw_Wj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.getOrCreate()\n",
        "print(spark)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmKaNLoppuX1",
        "outputId": "5a88869c-8980-452c-e78b-7b4d264ea133"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<pyspark.sql.session.SparkSession object at 0x7f9c73826e30>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import your Dataset (first pandas df then a spark df)\n",
        "Simple method: `df = pd.read_csv(\"https://github.com/YBIFoundation/Dataset/raw/main/IRIS.csv\")`"
      ],
      "metadata": {
        "id": "UHPgYcDnxCi-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the dataset into your spark session\n",
        "df = load_iris(as_frame=True)\n",
        "df = df.frame\n",
        "df = spark.createDataFrame(df)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4Md9SzKq_kb",
        "outputId": "a18c86ae-2b1d-4753-d17d-79d2a37eeccf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+----------------+-----------------+----------------+------+\n",
            "|sepal length (cm)|sepal width (cm)|petal length (cm)|petal width (cm)|target|\n",
            "+-----------------+----------------+-----------------+----------------+------+\n",
            "|              5.1|             3.5|              1.4|             0.2|     0|\n",
            "|              4.9|             3.0|              1.4|             0.2|     0|\n",
            "|              4.7|             3.2|              1.3|             0.2|     0|\n",
            "|              4.6|             3.1|              1.5|             0.2|     0|\n",
            "|              5.0|             3.6|              1.4|             0.2|     0|\n",
            "|              5.4|             3.9|              1.7|             0.4|     0|\n",
            "|              4.6|             3.4|              1.4|             0.3|     0|\n",
            "|              5.0|             3.4|              1.5|             0.2|     0|\n",
            "|              4.4|             2.9|              1.4|             0.2|     0|\n",
            "|              4.9|             3.1|              1.5|             0.1|     0|\n",
            "|              5.4|             3.7|              1.5|             0.2|     0|\n",
            "|              4.8|             3.4|              1.6|             0.2|     0|\n",
            "|              4.8|             3.0|              1.4|             0.1|     0|\n",
            "|              4.3|             3.0|              1.1|             0.1|     0|\n",
            "|              5.8|             4.0|              1.2|             0.2|     0|\n",
            "|              5.7|             4.4|              1.5|             0.4|     0|\n",
            "|              5.4|             3.9|              1.3|             0.4|     0|\n",
            "|              5.1|             3.5|              1.4|             0.3|     0|\n",
            "|              5.7|             3.8|              1.7|             0.3|     0|\n",
            "|              5.1|             3.8|              1.5|             0.3|     0|\n",
            "+-----------------+----------------+-----------------+----------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preliminary Checks on how the dataset looks like\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVMUywVctLvQ",
        "outputId": "974083e3-0f01-435e-f19a-3e797697faa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- sepal length (cm): double (nullable = true)\n",
            " |-- sepal width (cm): double (nullable = true)\n",
            " |-- petal length (cm): double (nullable = true)\n",
            " |-- petal width (cm): double (nullable = true)\n",
            " |-- target: long (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Club necessary features into a single vector using the VectorAssembler Module!"
      ],
      "metadata": {
        "id": "4euvvA8ZxOOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Group all the related features together as a single vector using the VectorAssembler\n",
        "featureassembler = VectorAssembler(inputCols=['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'], outputCol='Features')\n",
        "output_features = featureassembler.transform(df)\n",
        "output_features.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUZAKAojtfna",
        "outputId": "d2b99bc7-275b-4b91-ad0e-36365bcfab68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+----------------+-----------------+----------------+------+-----------------+\n",
            "|sepal length (cm)|sepal width (cm)|petal length (cm)|petal width (cm)|target|         Features|\n",
            "+-----------------+----------------+-----------------+----------------+------+-----------------+\n",
            "|              5.1|             3.5|              1.4|             0.2|     0|[5.1,3.5,1.4,0.2]|\n",
            "|              4.9|             3.0|              1.4|             0.2|     0|[4.9,3.0,1.4,0.2]|\n",
            "|              4.7|             3.2|              1.3|             0.2|     0|[4.7,3.2,1.3,0.2]|\n",
            "|              4.6|             3.1|              1.5|             0.2|     0|[4.6,3.1,1.5,0.2]|\n",
            "|              5.0|             3.6|              1.4|             0.2|     0|[5.0,3.6,1.4,0.2]|\n",
            "|              5.4|             3.9|              1.7|             0.4|     0|[5.4,3.9,1.7,0.4]|\n",
            "|              4.6|             3.4|              1.4|             0.3|     0|[4.6,3.4,1.4,0.3]|\n",
            "|              5.0|             3.4|              1.5|             0.2|     0|[5.0,3.4,1.5,0.2]|\n",
            "|              4.4|             2.9|              1.4|             0.2|     0|[4.4,2.9,1.4,0.2]|\n",
            "|              4.9|             3.1|              1.5|             0.1|     0|[4.9,3.1,1.5,0.1]|\n",
            "|              5.4|             3.7|              1.5|             0.2|     0|[5.4,3.7,1.5,0.2]|\n",
            "|              4.8|             3.4|              1.6|             0.2|     0|[4.8,3.4,1.6,0.2]|\n",
            "|              4.8|             3.0|              1.4|             0.1|     0|[4.8,3.0,1.4,0.1]|\n",
            "|              4.3|             3.0|              1.1|             0.1|     0|[4.3,3.0,1.1,0.1]|\n",
            "|              5.8|             4.0|              1.2|             0.2|     0|[5.8,4.0,1.2,0.2]|\n",
            "|              5.7|             4.4|              1.5|             0.4|     0|[5.7,4.4,1.5,0.4]|\n",
            "|              5.4|             3.9|              1.3|             0.4|     0|[5.4,3.9,1.3,0.4]|\n",
            "|              5.1|             3.5|              1.4|             0.3|     0|[5.1,3.5,1.4,0.3]|\n",
            "|              5.7|             3.8|              1.7|             0.3|     0|[5.7,3.8,1.7,0.3]|\n",
            "|              5.1|             3.8|              1.5|             0.3|     0|[5.1,3.8,1.5,0.3]|\n",
            "+-----------------+----------------+-----------------+----------------+------+-----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select only the necessary columns like the feature vector and the target column like the species column\n",
        "model_df = output_features.select('Features', 'target')\n",
        "model_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GC9d9kLOvJ9c",
        "outputId": "bf244af5-5041-4aa4-ceea-3dcb0566b735"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+------+\n",
            "|         Features|target|\n",
            "+-----------------+------+\n",
            "|[5.1,3.5,1.4,0.2]|     0|\n",
            "|[4.9,3.0,1.4,0.2]|     0|\n",
            "|[4.7,3.2,1.3,0.2]|     0|\n",
            "|[4.6,3.1,1.5,0.2]|     0|\n",
            "|[5.0,3.6,1.4,0.2]|     0|\n",
            "|[5.4,3.9,1.7,0.4]|     0|\n",
            "|[4.6,3.4,1.4,0.3]|     0|\n",
            "|[5.0,3.4,1.5,0.2]|     0|\n",
            "|[4.4,2.9,1.4,0.2]|     0|\n",
            "|[4.9,3.1,1.5,0.1]|     0|\n",
            "|[5.4,3.7,1.5,0.2]|     0|\n",
            "|[4.8,3.4,1.6,0.2]|     0|\n",
            "|[4.8,3.0,1.4,0.1]|     0|\n",
            "|[4.3,3.0,1.1,0.1]|     0|\n",
            "|[5.8,4.0,1.2,0.2]|     0|\n",
            "|[5.7,4.4,1.5,0.4]|     0|\n",
            "|[5.4,3.9,1.3,0.4]|     0|\n",
            "|[5.1,3.5,1.4,0.3]|     0|\n",
            "|[5.7,3.8,1.7,0.3]|     0|\n",
            "|[5.1,3.8,1.5,0.3]|     0|\n",
            "+-----------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split the dataset"
      ],
      "metadata": {
        "id": "onpToDya0jtY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the Dataset\n",
        "train_data, test_data = model_df.randomSplit([0.8, 0.2])"
      ],
      "metadata": {
        "id": "_ot0cbHRvfAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instantiate the model class and fit the dataset"
      ],
      "metadata": {
        "id": "WLMc15X30l4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Intiate the model object\n",
        "model = NaiveBayes(featuresCol='Features', labelCol='target')"
      ],
      "metadata": {
        "id": "9sJzh7WQzXZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the dataset\n",
        "model = model.fit(train_data)"
      ],
      "metadata": {
        "id": "g8YuJ_8-z_NT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Start the predictions using transform() method of the ML model class"
      ],
      "metadata": {
        "id": "uuDAVZCK0uBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions using Transform\n",
        "predictions = model.transform(test_data)"
      ],
      "metadata": {
        "id": "QvIi1kC-0F0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finding Accuracies and do the Math stuff!"
      ],
      "metadata": {
        "id": "zK2dgk4C1TVi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the accuracies counts\n",
        "predictions.groupBy('target', 'prediction').count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8R_2wSwR0Sht",
        "outputId": "cad7d679-7238-493d-dc17-3fa6cfd01895"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----------+-----+\n",
            "|target|prediction|count|\n",
            "+------+----------+-----+\n",
            "|     0|       0.0|   10|\n",
            "|     1|       1.0|   10|\n",
            "|     2|       2.0|   10|\n",
            "|     2|       1.0|    1|\n",
            "+------+----------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the confusion matrix\n",
        "predicted_values = predictions.select('prediction').collect()\n",
        "original_values = predictions.select('target').collect()\n",
        "cm = confusion_matrix(original_values, predicted_values)\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKZvNufl1HN8",
        "outputId": "d2f1e9b3-32ef-48dc-83ab-3e5efc5b1121"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[10  0  0]\n",
            " [ 0 10  0]\n",
            " [ 0  1 10]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = MulticlassClassificationEvaluator(labelCol='target', predictionCol='prediction')\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(f\"The final accuracy of the model is: {accuracy}\")\n",
        "print(f\"Test error of the model is: {1.0 - accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_R7ZSW43aZy",
        "outputId": "486d22cf-279c-4c3e-eacb-259a6c3a4df9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The final accuracy of the model is: 0.967741935483871\n",
            "Test error of the model is: 0.032258064516129004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WpSOmRwH5nvx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}